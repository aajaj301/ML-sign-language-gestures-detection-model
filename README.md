the project is an ML sign language gestures detection mode, specific for customized signs that can be found in the images file in the project.
Steps: 
1) Activate the virtual environment (tfod)
2) run the first 6 cells in the training file (Training and Detection.py )
3) then go directly to the checkpoints loading in part 8 in (Training and Detection.py)
4) run the real-time detection in part 10 in (Training and Detection.py )

## Acknowledgements

Special thanks to the contributors of [TFOD Course](https://github.com/nicknochnack/TFODCourse) for their valuable insights and code snippets that influenced and contributed to certain aspects of this project.
